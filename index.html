<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Vybestack</title>
  <style>
    body {
      margin: 0;
      padding: 4rem 2rem;
      background-color: #000;
      color: #6a9955;
      font-family: 'Courier New', Courier, monospace;
      line-height: 1.6;
      display: flex;
      flex-direction: column;
      align-items: center;
      max-width: 800px;
      margin-left: auto;
      margin-right: auto;
    }
    h1 {
      font-size: 3rem;
      font-weight: bold;
      line-height: 1.2;
      margin-bottom: 2rem;
      text-align: left;
      width: 100%;
    }
    h2 {
      font-size: 1.5rem;
      margin-top: 3rem;
      width: 100%;
      text-align: left;
    }
    p, ul {
      width: 100%;
      font-size: 1.1rem;
    }
    .features {
      margin: 1.5rem 0;
      padding-left: 1.5rem;
    }
    .features li {
      margin-bottom: 0.75rem;
    }
    .cta {
      margin-top: 2.5rem;
      width: 100%;
    }
    form {
      display: flex;
      flex-direction: column;
      max-width: 100%;
    }
    input[type="email"] {
      background-color: #000;
      border: 1px solid #6a9955;
      color: #6a9955;
      padding: 0.75rem;
      font-size: 1rem;
      font-family: inherit;
      margin-bottom: 1rem;
    }
    button {
      background-color: #6a9955;
      color: #000;
      font-size: 1rem;
      border: none;
      padding: 0.75rem;
      font-weight: bold;
      font-family: inherit;
      cursor: pointer;
      transition: background-color 0.2s ease-in-out;
    }
    button:hover {
      background-color: #85b47d;
    }
    footer {
      margin-top: 4rem;
      font-size: 1rem;
      opacity: 0.9;
      text-align: center;
    }
  </style>
</head>
<body>
  <h1>LLMs are powerful.<br>But only if you make them yours.</h1>

  <p>AI-first developer tools that give you control, not chaos.</p>

  <p>Vybestack is building the stack for developers who use LLMs like pros — with better memory, sharper context, and zero mystery middleware.</p>

  <p>Our first tool, <strong>LLxpert</strong>, brings intelligent coding to VSCode with multi-model support, local-first design, and actual context awareness.</p>

  <h2>Why it’s different</h2>
  <ul class="features">
    <li><strong>No backend. No lock-in.</strong> Your models, your keys.</li>
    <li><strong>Local or cloud —</strong> your choice.</li>
    <li><strong>Collaborate across models</strong> with LLM consensus.</li>
    <li><strong>Real memory. Real context.</strong> No vibes required.</li>
    <li><strong>AI-first workflows</strong> that don’t hijack your IDE.</li>
  </ul>

  <div class="cta">
    <p>We’re not launching yet. But we’re building for you.<br>
    Sign up for early access — and be the first to use LLM tools that actually understand your codebase.</p>

    <form action="https://formspree.io/f/mqaplrnd" method="POST">
      <input type="email" name="email" placeholder="you@domain.com" required />
      <button type="submit">Join the waitlist</button>
    </form>
  </div>

  <footer>
    <p>Not your copilot. Not your vibe.<br>
    Your tools. Your code. Your stack.</p>
  </footer>
</body>
</html>

