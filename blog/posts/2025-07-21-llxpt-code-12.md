# LLxprt Code 0.1.12 Released
*2025-07-21*

We're excited to announce the first public release of LLxprt Code, a community-driven fork of Google's gemini-cli that puts user choice and privacy first.

# What is LLxprt Code?

LLxprt Code is a CLI tool for interacting with AI models. While maintaining compatibility with the upstream gemini-cli, we're building something more: a CLI that works with any AI provider you choose - whether it's Gemini, OpenAI, Anthropic, or your own custom models.

## Installation

### Global install
  npm install -g @vybestack/llxprt-code

###   Or use npx
  npx @vybestack/llxprt-code

### Or Docker
  docker run -it ghcr.io/acoliver/llxprt-code/sandbox:0.1.12

### Or build from source
  git clone https://github.com/acoliver/llxprt-code
  npm install && npm run build

## For gemini-cli Users

If you're coming from gemini-cli, you'll find everything familiar. We track upstream changes. Our release numbers track Google's - LLxprt v0.1.12 is compatible with their v0.1.12. To get our first release out, our 0.1.12 is mid-cycle, but they'll track more closely after 0.1.13.

## For Claude Code Users

We love Claude Code and continue to use it. You'll note that frequently, some of our commits are signed by Claude. However, you've noticed the Claude Max plans are shrinking in what they offer. Other vendor tools, such as Cursor or Windsurf, have been increasing their prices. Having the option to use whatever model you want is going to be less of an optimization but a necessity in the near future. There is hope with exciting new open models and offers from providers like OpenRouter, Groq, and Fireworks. Max throttled you? Pop over to llxprt and get the job done.

## Our Approach

We're following a "Roo to their Cline" philosophy - tracking upstream for as long as practical while adding community-requested features. Key areas where we're diverging:

  - Multi-provider architecture: Clean provider abstraction with GeminiProvider.ts as the template
  - Privacy first: Telemetry removed entirely
  - User choice: No automatic model downgrades without user consent
  - Performance: Removing inefficient patterns like redundant Flash model checks that pass entire conversations multiple times

## Future Plans

Our release numbers will continue tracking Google's for compatibility, and our features will interleave their releases. We will focus on:

  - Multi-provider support
  - Worker/swarm capabilities
  - Performance and Architectural Improvements
  
Initially, we're just merging main from Gemini CLI every few days. We've already diverged a bit by fixing some React architectural issues (and our skinning is more complete). As time passes, we will adopt a selective merging strategy as we diverge.

However, the future depends on you!!

# Join Us

  This is a community project. We've already had fantastic feedback from early testers who reported issues before we even released. Now we need:

  - Your bug reports and feature requests
  - Pull requests
  - Contributors who want to become maintainers

  Let's build the CLI for us - one that works with whatever model, from whatever provider, however we want to use it.

  Thank you for your interest and support. We look forward to building this together!!

  ---
  Repository: https://github.com/acoliver/llxprt-code
  NPM: https://www.npmjs.com/package/@vybestack/llxprt-code
