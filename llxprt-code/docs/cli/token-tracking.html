<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Token Tracking | LLxprt Code Docs</title>
  <link rel="stylesheet" href="../../../vybestack.css" />
</head>
<body>

  <nav>
    <div class="nav-container">
      <div class="nav-left">
        <a href="/" class="logo">
          <img src="/assets/vybestack_logo.png" alt="Vybestack" />
        </a>
        <span class="tagline">Beyond Vibe Coding</span>
      </div>
      <div class="nav-right">
        <div class="nav-dropdown">
          <a href="/llxprt-code.html">LLxprt Code</a>
          <div class="nav-dropdown-menu">
            <a href="/llxprt-code.html">Overview</a>
            <a href="/llxprt-code/docs/">Documentation</a>
          </div>
        </div>
        <a href="/jefe.html">LLxprt Jefe</a>
        <a href="/blog/">Blog</a>
        <a href="/#podcast">Podcast</a>
        <a href="https://discord.gg/Wc6dZqWWYv" target="_blank">Discord</a>
      </div>
    </div>
  </nav>


  <section class="section docs-section">
    <div class="container-wide">
      <div class="docs-layout">

      <nav class="docs-sidebar">
        <h3><a href="/llxprt-code/docs/">Documentation</a></h3>
        <ul>
          <li><a href="/llxprt-code/docs/getting-started.html">Getting Started Guide</a></li>
          <li><a href="/llxprt-code/docs/cli/providers.html">Provider Configuration</a></li>
          <li><a href="/llxprt-code/docs/cli/authentication.html">Authentication</a></li>
          <li><a href="/llxprt-code/docs/cli/profiles.html">Profiles</a></li>
          <li><a href="/llxprt-code/docs/sandbox.html">Sandboxing</a></li>
          <li><a href="/llxprt-code/docs/subagents.html">Subagents</a></li>
          <li><a href="/llxprt-code/docs/oauth-setup.html">OAuth Setup</a></li>
          <li><a href="/llxprt-code/docs/local-models.html">Local Models</a></li>
          <li><a href="/llxprt-code/docs/zed-integration.html">Zed Editor Integration</a></li>
          <li><a href="/llxprt-code/docs/cli/providers-openai-responses.html">OpenAI Responses API</a></li>
          <li><a href="/llxprt-code/docs/prompt-configuration.html">Prompt Configuration</a></li>
          <li><a href="/llxprt-code/docs/settings-and-profiles.html">Settings and Profiles</a></li>
          <li><a href="/llxprt-code/docs/checkpointing.html">Checkpointing</a></li>
          <li><a href="/llxprt-code/docs/extension.html">Extensions</a></li>
          <li><a href="/llxprt-code/docs/ide-integration.html">IDE Integration</a></li>
          <li><a href="/llxprt-code/docs/cli/configuration.html">Configuration</a></li>
          <li><a href="/llxprt-code/docs/cli/commands.html">Commands Reference</a></li>
          <li><a href="/llxprt-code/docs/troubleshooting.html">Troubleshooting Guide</a></li>
          <li><a href="/llxprt-code/docs/cli/index.html">CLI Introduction</a></li>
          <li><a href="/llxprt-code/docs/deployment.html">Execution and Deployment</a></li>
          <li><a href="/llxprt-code/docs/keyboard-shortcuts.html">Keyboard Shortcuts</a></li>
          <li><a href="/llxprt-code/docs/cli/themes.html">Themes</a></li>
          <li><a href="/llxprt-code/docs/EMOJI-FILTER.html">Emoji Filter</a></li>
          <li><a href="/llxprt-code/docs/cli/runtime-helpers.html">Runtime helper APIs</a></li>
          <li><a href="/llxprt-code/docs/cli/context-dumping.html">Context Dumping</a></li>
          <li><a href="/llxprt-code/docs/telemetry.html">Telemetry</a></li>
          <li><a href="/llxprt-code/docs/telemetry-privacy.html">Telemetry Privacy</a></li>
          <li><a href="/llxprt-code/docs/gemini-cli-tips.html">Migration from Gemini CLI</a></li>
          <li><a href="/llxprt-code/docs/architecture.html">Architecture Overview</a></li>
          <li><a href="/llxprt-code/docs/core/index.html">Core Introduction</a></li>
          <li><a href="/llxprt-code/docs/core/provider-runtime-context.html">Provider runtime context</a></li>
          <li><a href="/llxprt-code/docs/core/provider-interface.html">Provider interface</a></li>
          <li><a href="/llxprt-code/docs/core/tools-api.html">Tools API</a></li>
          <li><a href="/llxprt-code/docs/core/memport.html">Memory Import Processor</a></li>
          <li><a href="/llxprt-code/docs/shell-replacement.html">Shell Replacement</a></li>
          <li><a href="/llxprt-code/docs/../CONTRIBUTING.html">Contributing & Development Guide</a></li>
          <li><a href="/llxprt-code/docs/npm.html">NPM Workspaces and Publishing</a></li>
          <li><a href="/llxprt-code/docs/migration/stateless-provider.html">Stateless provider migration</a></li>
          <li><a href="/llxprt-code/docs/tools/index.html">Tools Overview</a></li>
          <li><a href="/llxprt-code/docs/tools/file-system.html">File System Tools</a></li>
          <li><a href="/llxprt-code/docs/tools/multi-file.html">Multi-File Read Tool</a></li>
          <li><a href="/llxprt-code/docs/tools/shell.html">Shell Tool</a></li>
          <li><a href="/llxprt-code/docs/tools/mcp-server.html">MCP Server</a></li>
          <li><a href="/llxprt-code/docs/tools/web-fetch.html">Web Fetch Tool</a></li>
          <li><a href="/llxprt-code/docs/tools/web-search.html">Web Search Tool</a></li>
          <li><a href="/llxprt-code/docs/tools/memory.html">Memory Tool</a></li>
          <li><a href="/llxprt-code/docs/release-notes/stateless-provider.html">Release notes: Stateless Provider</a></li>
          <li><a href="/llxprt-code/docs/tos-privacy.html">Terms of Service and Privacy Notice</a></li>
        </ul>
      </nav>
        <div class="docs-content">
          <div class="blog-post-content">
            <h1>Token Tracking</h1>
<h2>Overview</h2>
<p>LLxprt Code provides real-time token tracking capabilities to help you monitor your API usage across multiple providers. The token tracking feature displays:</p>
<ul>
<li><strong>TPM (Tokens Per Minute)</strong>: The rate of output token generation</li>
<li><strong>Session Tokens</strong>: Cumulative token usage for your current session</li>
<li><strong>Throttle Wait Time</strong>: Total time spent waiting for rate limit retries</li>
</ul>
<h2>Features</h2>
<h3>Real-Time Metrics in Footer</h3>
<p>The footer displays live token metrics that update as you use the CLI:</p>
<pre><code>TPM: 2450.75 | Tokens: 125k | Wait: 6.2s
</code></pre>
<ul>
<li><strong>TPM</strong>: Shows output tokens per minute (only output tokens, not input)</li>
<li><strong>Tokens</strong>: Total session tokens (input + output + cache + tool + thought)</li>
<li><strong>Wait</strong>: Accumulated wait time from 429 rate limit retries</li>
</ul>
<h3>Provider Support</h3>
<p>Token tracking works with all supported providers:</p>
<ul>
<li>OpenAI (requires <code>stream_options: { include_usage: true }</code>)</li>
<li>Anthropic (built-in usage tracking)</li>
<li>Gemini (built-in usage tracking)</li>
<li>Other providers as they add usage metadata</li>
</ul>
<h3>No Logging Required</h3>
<p>Token tracking works independently of conversation logging. You don't need to enable logging to see token metrics.</p>
<h2>Configuration</h2>
<p>Token tracking is enabled by default. No configuration is required.</p>
<h3>Ephemeral Settings</h3>
<p>You can control retry behavior (which affects throttle tracking) using ephemeral settings:</p>
<pre><code class="language-bash"># Set max retries
/ephemeral retries 6

# Set initial retry wait time (ms)
/ephemeral retrywait 1000
</code></pre>
<h2>Commands</h2>
<h3>View Detailed Stats</h3>
<p>Use the <code>/stats</code> command to see detailed token usage breakdown:</p>
<pre><code class="language-bash">/stats
</code></pre>
<p>This shows:</p>
<ul>
<li>Token usage by type (input, output, cache, tool, thought)</li>
<li>Provider-specific metrics</li>
<li>Historical usage patterns</li>
</ul>
<h3>Diagnostics</h3>
<p>The <code>/diagnostics</code> command includes token tracking metrics:</p>
<pre><code class="language-bash">/diagnostics
</code></pre>
<h2>Understanding the Metrics</h2>
<h3>TPM (Tokens Per Minute)</h3>
<ul>
<li>Calculated using a sliding 60-second window</li>
<li>Shows only output tokens (the tokens the model generates)</li>
<li>Updates in real-time as responses stream in</li>
<li>Helps you understand generation speed and identify throttling</li>
</ul>
<h3>Session Tokens</h3>
<ul>
<li>Accumulates all token types across the session</li>
<li>Resets when you start a new session</li>
<li>Includes:
<ul>
<li><strong>Input</strong>: Tokens from your prompts</li>
<li><strong>Output</strong>: Tokens from model responses</li>
<li><strong>Cache</strong>: Cached context tokens (provider-specific)</li>
<li><strong>Tool</strong>: Tokens used for tool calls</li>
<li><strong>Thought</strong>: Internal reasoning tokens (provider-specific)</li>
</ul>
</li>
</ul>
<h3>Throttle Wait Time</h3>
<ul>
<li>Tracks cumulative time spent waiting due to rate limits (429 errors)</li>
<li>Helps identify when you're hitting provider limits</li>
<li>Accumulates across all retries in the session</li>
</ul>
<h2>Provider-Specific Notes</h2>
<h3>OpenAI</h3>
<ul>
<li>Requires streaming responses for real-time tracking</li>
<li>Token counts available via <code>usage</code> field in responses</li>
<li>Automatically disables OpenAI SDK's built-in retries to track throttles</li>
</ul>
<h3>Anthropic</h3>
<ul>
<li>Native usage tracking in all responses</li>
<li>Includes cache tokens for context caching</li>
<li>Thought tokens for Claude's thinking process</li>
</ul>
<h3>Gemini</h3>
<ul>
<li>Built-in token counting</li>
<li>May show different token counts due to tokenizer differences</li>
</ul>
<h2>Troubleshooting</h2>
<h3>TPM Shows 0</h3>
<ul>
<li>Ensure you're using a provider that returns usage data</li>
<li>Check that streaming is enabled</li>
<li>Verify the provider is configured correctly</li>
</ul>
<h3>Throttle Time Not Updating</h3>
<ul>
<li>Only tracks 429 rate limit errors</li>
<li>Some providers handle retries internally</li>
<li>Check ephemeral settings for retry configuration</li>
</ul>
<h3>Session Tokens Not Accumulating</h3>
<ul>
<li>Verify provider is returning usage metadata</li>
<li>Check that token tracking isn't disabled</li>
<li>Ensure provider wrapper is properly configured</li>
</ul>
<h2>Technical Details</h2>
<p>Token tracking is implemented through:</p>
<ul>
<li><code>ProviderPerformanceTracker</code>: Calculates TPM and tracks metrics</li>
<li><code>LoggingProviderWrapper</code>: Extracts token counts from responses</li>
<li><code>ProviderManager</code>: Accumulates session-wide token usage</li>
<li>UI components poll metrics every second for live updates</li>
</ul>
<p>The feature has minimal performance impact and doesn't affect response times.</p>

          </div>
        </div>
      </div>
    </div>
  </section>


  <footer class="footer">
    <div class="footer-container">
      <div class="footer-section">
        <h4>Vybestack</h4>
        <p>Beyond vibe coding. Autonomous development for ascending engineers.</p>
      </div>
      <div class="footer-section">
        <h4>Products</h4>
        <ul>
          <li><a href="/llxprt-code.html">LLxprt Code</a></li>
          <li><a href="/jefe.html">LLxprt Jefe</a></li>
        </ul>
      </div>
      <div class="footer-section">
        <h4>Content</h4>
        <ul>
          <li><a href="/blog/">Blog</a></li>
          <li><a href="/#podcast">Podcast</a></li>
          <li><a href="/llxprt-code/docs/">Documentation</a></li>
        </ul>
      </div>
      <div class="footer-section">
        <h4>Connect</h4>
        <ul class="footer-icons">
<li><a href="https://github.com/vybestack/llxprt-code"><img src="/assets/icons/github.svg" alt="GitHub" /> </a></li>
<li><a href="https://discord.gg/Wc6dZqWWYv"><img src="/assets/icons/discord.svg" alt="Discord" /></a></li>
<li><a href="https://www.linkedin.com/company/vybestack/"><img src="/assets/icons/linkedin.svg" alt="LinkedIn" /></a></li>
        </ul>
      </div>
    </div>
    <div class="footer-bottom">
      <p>&copy; 2026 Vybestack. Apache 2.0 License. Built for the terminal.</p>
    </div>
  </footer>

</body>
</html>